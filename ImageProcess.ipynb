{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNirTnb33CnH/KnabAMvoYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RangsimanDev/ImageProcessing/blob/main/ImageProcess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQvvAdrcL0_C"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import cv2 as cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "np.random.seed(1)\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os, os.path\n",
        "from os import walk\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "print(\"Connect Google Drive Success!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data from Train\n",
        "pathD_train =  '/content/drive/MyDrive/Project-Data/Durian/Train/' #ใส่ path\n",
        "nameDir =  ['Unripe','Ripe']\n",
        "num_class=2\n",
        "\n",
        "target_train=[]\n",
        "y_train_one_hot=[]\n",
        "data_train=[]\n",
        "for i in range(len(nameDir)) :\n",
        "  print(i)\n",
        "  num_target=str(i)\n",
        "  print(pathD_train+nameDir[i])\n",
        "  path, dirs, files = next(os.walk(pathD_train+nameDir[i]))  #ใส่ path\n",
        "  len_file = len(files)\n",
        "  for j in range(len_file):\n",
        "    num_pic=str(j+1)\n",
        "    print(str(pathD_train)+nameDir[i]+\"/\"+num_target+\" (\"+num_pic+\").jpg\" )\n",
        "    img = Image.open(str(pathD_train)+nameDir[i]+\"/\"+num_target+\" (\"+num_pic+\").jpg\" ) #ใส่ path\n",
        "    img =  img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    data_train.append(img) #ใส่ ตัวแปรเก็บข้อมูลให้ถูก\n",
        "    target_train.append([int(num_target)]) #ใส่ ตัวแปรเก็บข้อมูลtargetให้ถูก\n",
        "    #target.append(encoder.transform([[int(num_target)]]).toarray())\n",
        "    y_train_one_hot.extend([list([eval(num_target)])]) #ใส่ ตัวแปรเก็บข้อมูลtargetแบบ encode ให้ถูก\n",
        "\n",
        "\n",
        "data_train=np.asarray(data_train)\n",
        "target_train=np.asarray(target_train)\n",
        "data_train = (data_train/ 255.0)\n",
        "from keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train_one_hot)\n",
        "from sklearn.utils import shuffle\n",
        "data_train, target_train = shuffle(data_train, target_train)"
      ],
      "metadata": {
        "id": "zLGkhWZTMqzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data from Test\n",
        "pathD_test =  '/content/drive/MyDrive/Project-Data/Durian/Test/' #ใส่ path\n",
        "nameDir =  ['Unripe','Ripe']\n",
        "num_class=2\n",
        "target_test=[]\n",
        "y_test_one_hot=[]\n",
        "data_test=[]\n",
        "for i in range(len(nameDir)) :\n",
        "  print(i)\n",
        "  num_target=str(i)\n",
        "  path, dirs, files = next(os.walk(pathD_test+nameDir[i]))  #ใส่ path\n",
        "  len_file = len(files)\n",
        "  for j in range(len_file):\n",
        "    num_pic=str(j+1)\n",
        "    img = Image.open(str(pathD_test)+nameDir[i]+\"/\"+num_target+\" (\"+num_pic+\").jpg\" ) #ใส่ path\n",
        "    img =  img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    data_test.append(img) #ใส่ ตัวแปรเก็บข้อมูลให้ถูก\n",
        "    target_test.append([int(num_target)]) #ใส่ ตัวแปรเก็บข้อมูลtargetให้ถูก\n",
        "    y_test_one_hot.extend([list([eval(num_target)])]) #ใส่ ตัวแปรเก็บข้อมูลtargetแบบ encode ให้ถูก\n",
        "\n",
        "\n",
        "data_test=np.asarray(data_test)\n",
        "target_test=np.asarray(target_test)\n",
        "data_test = (data_test/ 255.0)\n",
        "from keras.utils import to_categorical\n",
        "y_test_one_hot = to_categorical(y_test_one_hot )\n",
        "from sklearn.utils import shuffle\n",
        "data_test, target_test = shuffle(data_test, target_test)"
      ],
      "metadata": {
        "id": "vNTS-CJePeLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Conv2D , MaxPooling2D ,GlobalAveragePooling2D ,Flatten , Dense , Dropout\n",
        "\n",
        "#from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "#initialize the CNN\n",
        "model = Sequential()\n",
        "#Step1-Convolution\n",
        "#32 filters (3x3), img 64x63 RGB\n",
        "model.add(Conv2D(32,kernel_size=(3, 3), strides=(1, 1), input_shape=(224, 224, 3), padding='same', activation='relu'))\n",
        "#Step2-MaxPooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "#Step3-Flattening\n",
        "model.add(Flatten())\n",
        "#Step4-Full Connection\n",
        "#first layer has 128 neurons and the activation function ReLu.\n",
        "#last layer of this neural network with 10 neurons (one for each label) using the sigmoid function.\n",
        "model.add(Dense(units = 128,  activation ='relu'))\n",
        "model.add(Dense(units = 2))\n",
        "#Compiling the CNN\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "P_U1zwI9PkC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#สร้าง โมเดล CNN\n",
        "import tensorflow as tf\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(data_train, target_train, epochs=10,\n",
        "                    validation_data=(data_test, target_test))"
      ],
      "metadata": {
        "id": "e4RpAYFDQWjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4H2QV5CCgY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], label='accuracy') #ของ Train\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(data_test,  target_test, verbose=2)"
      ],
      "metadata": {
        "id": "9xi0TpN3Q9UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,f1_score, precision_score, recall_score\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "y_true=target_test.reshape(10,) #กำหนดให้มันมีรูปแบบเป็น array 1 มิติที่มีความยาว 10\n",
        "#y_true = np.argmax(target_test, axis=1)\n",
        "y_pred = np.argmax(model.predict(data_test), axis=1)\n",
        "data = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "df_cm.index.name = 'Actual' #ค่าจริง\n",
        "df_cm.columns.name = 'Predicted' #ค่าคาดการณ์\n",
        "plt.figure(figsize = (6,5))\n",
        "sn.set(font_scale=1.4)#for label size\n",
        "#sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size\n",
        "\n",
        "sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"plasma\");"
      ],
      "metadata": {
        "id": "o9JEz7LyRBso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/github/syamkakarla98/Face_Recognition_Using_Convolutional_Neural_Networks/blob/master/CNN.ipynb#scrollTo=KeUCfJC_MADK\n",
        "def plot_predictions(r=5 ,c =1):\n",
        "  w=10\n",
        "  h=10\n",
        "  fig=plt.figure(figsize=(12, 20))\n",
        "  columns = c\n",
        "  rows = r\n",
        "  for i in range(1, columns*rows +1):\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      rand_n = np.random.randint(data_test.shape[0])\n",
        "\n",
        "      plt.imshow(data_test[rand_n][:, :, :])\n",
        "      #print(rand_n)\n",
        "      plt.title(f'Actual:{y_true[rand_n]} Predicted: {np.argmax(model.predict(data_test[rand_n].reshape(-1, 224, 224, 3)))}',fontsize = 9)\n",
        "      plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2Dbem8-ZRzl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " plot_predictions()"
      ],
      "metadata": {
        "id": "aGPIrXtCR12Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}